from plaid import Client
import os
import pandas as pd
import json
import pickle
from google_auth_httplib2 import Request
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build

# Заполняем данные для авторизации в Plaid
os.environ['PLAID_CLIENT_ID'] = '5ecd645255135b0011c7728e'
os.environ['PLAID_SECRET'] = 'c41d1035b22e295281da315a5d1a86'
os.environ['PLAID_PUBLIC_KEY'] = '936393cc72b3e887f7828d262ee0b7'
os.environ['PLAID_PRODUCTS'] = 'transactions'
os.environ['PLAID_COUNTRY_CODES'] = 'US'
os.environ['PLAID_ENV'] = 'sandbox'
access_token = 'access-sandbox-2dcad8c5-bc38-4667-81aa-d449a09d94b1'
PLAID_CLIENT_ID = os.getenv('PLAID_CLIENT_ID')
PLAID_SECRET = os.getenv('PLAID_SECRET')
PLAID_PUBLIC_KEY = os.getenv('PLAID_PUBLIC_KEY')
PLAID_ENV = os.getenv('PLAID_ENV', 'sandbox')

# Выгружаем транзакции Bank of America из PLAID
client = Client(client_id=PLAID_CLIENT_ID, secret=PLAID_SECRET
                , public_key=PLAID_PUBLIC_KEY, environment=PLAID_ENV)
response = client.Transactions.get(access_token, start_date='1700-01-01', end_date='2999-01-01')
transactions = response['transactions']
while len(transactions) < response['total_transactions']:
    response = client.Transactions.get(access_token, start_date='1700-01-01', end_date='2999-01-01',
                                       offset=len(transactions)
                                       )
    transactions.extend(response['transactions'])

# Сохраняем в dataframe
df = pd.read_json(json.dumps(transactions))


# функция для извлечения столбцов из json
def get_col(complex_object, col_index=0):
    if col_index <= len(complex_object) - 1:
        return complex_object[col_index]
    else:
        return 'null'


# извлекаем и добавляем в новые столбцы категории и подкатегории
df['Category 1'] = df.category.apply(lambda x: get_col(x, 0))
df['Category 2'] = df.category.apply(lambda x: get_col(x, 1))

# создаем флаг, который позволит сгруппировать расходы и доходы
df['Income/Expense'] = 'Expense'
df.loc[(df.amount >= 0), 'Income/Expense'] = 'Income'

# для группировки в google-sheets по образцу, создаем столбец месяц-год
df['new_date'] = df.date.dt.strftime('%b %Y')

# удаляем лишние столбцы, оставляем transaction_id как уникальный ключ
df = df[['transaction_id', 'date', 'new_date', 'Category 1', 'Category 2', 'Income/Expense', 'amount']]

# Заполняем данные для авторизации в Google sheets
CLIENT_SECRET_FILE = 'google_secret.json'
API_SERVICE_NAME = 'sheets'
API_VERSION = 'v4'
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
spreadsheetId = '1NAxfaMrbm-TaiUpfAecB3ibG6Esg7e7ybYldyrQjKZ8'

# подключаемся к Google sheets
def Create_Service(client_secret_file, api_name, api_version, *scopes):
    print(client_secret_file, api_name, api_version, scopes, sep='-')
    CLIENT_SECRET_FILE = client_secret_file
    API_SERVICE_NAME = api_name
    API_VERSION = api_version
    SCOPES = [scope for scope in scopes[0]]
    print(SCOPES)

    cred = None

    pickle_file = f'token_{API_SERVICE_NAME}_{API_VERSION}.pickle'

    if os.path.exists(pickle_file):
        with open(pickle_file, 'rb') as token:
            cred = pickle.load(token)

    if not cred or not cred.valid:
        if cred and cred.expired and cred.refresh_token:
            cred.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(
                CLIENT_SECRET_FILE, SCOPES)
            cred = flow.run_local_server()

        with open(pickle_file, 'wb') as token:
            pickle.dump(cred, token)

    try:
        service = build(API_SERVICE_NAME, API_VERSION, credentials=cred)
        print(API_SERVICE_NAME, 'service created successfully')
        return service
    except Exception as e:
        print(e)
    return None

service = Create_Service(CLIENT_SECRET_FILE, API_SERVICE_NAME, API_VERSION, SCOPES)

# Сохраняем транзакции Bank of America в Google sheets
response_date = service.spreadsheets().values().append(
    spreadsheetId=spreadsheetId,
    valueInputOption='RAW',
    range='transactions!A1',
    body=dict(
        majorDimension='ROWS',
        values=df.T.reset_index().T.values.tolist())
).execute()
